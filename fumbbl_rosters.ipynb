{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New analysis goal: fixed skill sets from tourneys\n",
    "\n",
    "Use df_matches to identify the group ids that use competitive rulesets.\n",
    "This gives us the team ids we need.\n",
    "Then we can get the team roster using https://fumbbl.com/api/team/get/1102662\n",
    "we need the player ids here.\n",
    "\n",
    "and the chosen skills using https://fumbbl.com/api/team/getOptions/1102662\n",
    "this is a string of player ids, with skill ids.\n",
    "\n",
    "through https://fumbbl.com/api/skill/list we can get a list of skills.\n",
    "https://fumbbl.com/api/skill/list/2020 and this is the 2020 list.\n",
    "\n",
    "* World cup training: 9941 (dec 2020), 2 matches in dec 2020 using bb2016, then in okt 2021 for real. 429 matches.\n",
    "* SUper league: 15615\n",
    "* templars road to WC: 11605\n",
    "* entrainment tournois: 12879\n",
    "* NAF online tournaments : 9298\n",
    "* Tacklezone: 12013\n",
    "* Doppelbock: 13198\n",
    "* Eurobowl practice league: 15643\n",
    "* Eurobowl 2020 training: 12087 (eurobowl warsaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import requests\n",
    "\n",
    "from mizani.formatters import date_format\n",
    "\n",
    "# point this to the location of the HDF5 datasets\n",
    "path_to_datasets = 'datasets/current/'\n",
    "\n",
    "# FUMBBL matches\n",
    "target = 'df_matches.h5'\n",
    "df_matches = pd.read_hdf(path_to_datasets + target) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUMBBL inducements\n",
    "target = 'inducements.h5'\n",
    "inducements = pd.read_hdf(path_to_datasets + target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_matches.query('match_id == 4257923')['team1_id']\n",
    "df_matches.query('league == 12013 & team1_value < 1000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inducements.query('match_id == 4335359')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch skill code list\n",
    "%run read_json_file.py\n",
    "%run write_json_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_string = \"https://fumbbl.com/api/skill/list/2020\"\n",
    "\n",
    "skill_list = requests.get(api_string)\n",
    "# PM here save JSON as file\n",
    "skill_list = skill_list.json()\n",
    "\n",
    "write_json_file(skill_list, fname = \"cache/skill_list_bb2020.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_list = read_json_file(fname = \"cache/skill_list_bb2020.json\")\n",
    "skill_list = pd.json_normalize(skill_list)\n",
    "skill_list.rename({'id' : 'skill_id'}, axis = 1, inplace=True)\n",
    "\n",
    "skill_list = skill_list.loc[:, ['skill_id', 'name']]\n",
    "\n",
    "skill_list.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.query('league == 9941 and match_date > \"2021-09-20\" & team1_value < 1000')\n",
    "#df_matches.query('league == 9941')['team2_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Team roster info\n",
    "\n",
    "Need a combi of Team and Match to get the inducements for the roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches['match_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_id, team_id = [4337210, 1050197] # 1150\n",
    "match_id, team_id = [4261575, 1000657] # 880 no skills + SP\n",
    "match_id, team_id = [4261575, 1000538] # 780no skills + SP\n",
    "match_id, team_id = [4335316, 1050180] # 875 w skills + SP\n",
    "match_id, team_id = [4339241,1052367] # 810 w skills + SP\n",
    "match_id, team_id = [4377476,1075377] # 925 w skills + SP\t\n",
    "match_id, team_id = [4378237, 1075893] # 820 w skills, SP and bribe\n",
    "match_id, team_id = [4381569, 1078092]\n",
    "\n",
    "\n",
    "api_string = \"https://fumbbl.com/api/team/get/\" + str(team_id)\n",
    "\n",
    "team = requests.get(api_string)\n",
    "# PM here save JSON as file\n",
    "team = team.json()\n",
    "\n",
    "write_json_file(team, fname = 'cache/' + str(team_id) + \".json\")\n",
    "\n",
    "api_string = \"https://fumbbl.com/api/team/getOptions/\" + str(team_id)\n",
    "\n",
    "r = requests.get(api_string)\n",
    "r = r.json()\n",
    "# the following row is required to dodge this bug #203:\n",
    "r['tournamentSkills'] = json.loads(r['tournamentSkills'])\n",
    "\n",
    "write_json_file(r, fname = 'cache/' + str(team_id) + \"_skills.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://fumbbl.com/api/ruleset/get/188\n",
    "contains info about gold and skills.\n",
    "\n",
    "From the roster id we can infer the bb version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'cache/' + str(team_id) + '.json'\n",
    "\n",
    "team_obj = read_json_file(fname)\n",
    "team_obj\n",
    "\n",
    "fname = 'cache/' + str(team_id) + '_skills.json'\n",
    "team_skill_obj = read_json_file(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract the player info into a nice pd dataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roster = pd.json_normalize(team_obj, 'players', ['rerolls', 'assistantCoaches', 'cheerleaders', 'apothecary', ['roster', 'name']])\n",
    "\n",
    "df_roster.rename({'id' : 'player_id'}, axis = 1, inplace = True)\n",
    "\n",
    "df_roster = df_roster.loc[:, ['player_id', 'number', 'position', 'rerolls', 'assistantCoaches', 'cheerleaders', 'apothecary', 'roster.name']]\n",
    "\n",
    "df_roster['team_id'] = team_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_skill_obj\n",
    "\n",
    "pd_skills = pd.json_normalize(team_skill_obj, 'tournamentSkills')\n",
    "\n",
    "pd_skills.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we add the skill info to the roster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_skills = pd.json_normalize(team_skill_obj, 'tournamentSkills')\n",
    "\n",
    "if pd_skills.empty is False:    \n",
    "    pd_skills.columns = ['player_id', 'skill_id']\n",
    "\n",
    "    pd_skills['player_id'] = pd_skills['player_id'].fillna(0).astype(np.int64)\n",
    "    pd_skills['skill_id'] = pd_skills['skill_id'].fillna(0).astype(np.int64)\n",
    "\n",
    "else:\n",
    "    pd_skills = pd.DataFrame({'player_id': [-1], 'skill_id': [-1]})\n",
    "\n",
    "# Next we add the skill names:\n",
    "pd_skills= pd.merge(pd_skills, skill_list, on='skill_id', how='left')\n",
    "pd_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we combine the skills with the roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_roster = pd.merge(df_roster, pd_skills, on='player_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add the inducements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (df_matches.query('match_id == @match_id')['team1_id'].values[0] == team_id):\n",
    "    inducement_id = 'team1'\n",
    "elif (df_matches.query('match_id == @match_id')['team2_id'].values[0] == team_id):\n",
    "    inducement_id = 'team2'\n",
    "else:\n",
    "    inducement_id = -1\n",
    "\n",
    "inducements_to_add = inducements.query('match_id == @match_id and team == @inducement_id')['inducements'].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "inducements_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inducement in inducements_to_add:\n",
    "    if not inducement == ['']:\n",
    "        new_row = df_roster.iloc[[1]].copy()\n",
    "        new_row['position'] = inducement\n",
    "        new_row['player_id'] = 99999999\n",
    "        new_row['number'] = 99\n",
    "        new_row['skill_id'] = np.NaN\n",
    "        new_row['name'] = np.nan\n",
    "        df_roster = df_roster.append(new_row)\n",
    "\n",
    "df_roster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('requests_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50276fd1884268afe39607052f22ef19b84d915691d702a5c7e9a67a09867105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
